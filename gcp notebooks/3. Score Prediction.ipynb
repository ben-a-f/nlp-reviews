{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9d06d40-d232-424b-b2ad-49c0490eee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from google.cloud import storage\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0525aafb-7c1a-44b8-b257-7d85147676a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"bf-review-nlp\"\n",
    "blob_name = \"processed_data/processed_df.pickle\"\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(blob_name)\n",
    "pickle_data = blob.download_as_bytes()\n",
    "pickle_file = io.BytesIO(pickle_data)\n",
    "df_raw = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef00f33-3643-4bb8-b802-0675f6af4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 79122 entries, 256187 to 892717\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   overall      79122 non-null  category\n",
      " 1   verified     79122 non-null  bool    \n",
      " 2   style        65261 non-null  object  \n",
      " 3   reviewText   79122 non-null  object  \n",
      " 4   stemmedText  79122 non-null  object  \n",
      "dtypes: bool(1), category(1), object(3)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Trim dataset for runtime\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "X_raw = df_raw[\"stemmedText\"]\n",
    "y_raw = df_raw[\"overall\"]\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.05, random_state=42)\n",
    "_, idx = next(stratified_split.split(X_raw, y_raw))\n",
    "\n",
    "df = df_raw.iloc[idx]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35bdb50-83c6-4e6c-8e1c-bd6673d3ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the report into a DataFrame\n",
    "def csv_report(report, name):\n",
    "    lines = report.split('\\n')\n",
    "    data = [line.split()[1:] for line in lines[2:-5]]\n",
    "    columns = ['precision', 'recall', 'f1-score', 'support']\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    output_csv_path = name+\".csv\"\n",
    "    df.to_csv(output_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57236331-696b-4c7f-be8b-df05f937ff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "X = vectorizer.fit_transform(df['stemmedText'])\n",
    "y = df[\"overall\"]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(stratified_split.split(X, y))\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "y_test = y.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c2f9c2-42dc-4276-b29b-1a0c79eba101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialise and run model using a grid search to find parameters, and evaluating using f1-score with cross-validation.\n",
    "# We could do a much more comprehensive parameter search, but due to computation time on my machine, we'll keep it small.\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf_params = {'max_depth': [None, 10],\n",
    "             'min_samples_split': [10, 20],\n",
    "             'min_samples_leaf': [4, 8]}\n",
    "\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring=\"f1_macro\")\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best_params = rf_grid.best_params_\n",
    "\n",
    "best_rf = RandomForestClassifier(**rf_best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "rf_pred = best_rf.predict(X_test)\n",
    "rf_report = classification_report(y_test, rf_pred)\n",
    "csv_report(rf_report, \"rf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c1f3608-3f65-4506-a913-cf6b26d15b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try class weighting due to imbalanced classes.\n",
    "# This is less computationally expensive than oversampling, and the dataset is already large (and slow).\n",
    "# Ideally we'd re-do a grid search, but for the sake of computation time we'll just re-use our parameters from earlier.\n",
    "class_weights = compute_class_weight('balanced', classes=y_train.unique(), y=y_train)\n",
    "class_weight_dict = dict(zip(y_train.unique(), class_weights))\n",
    "\n",
    "rf_weighted = RandomForestClassifier(**rf_best_params, class_weight=class_weight_dict, random_state=42)\n",
    "rf_weighted.fit(X_train, y_train)\n",
    "rf_wighted_pred = rf_weighted.predict(X_test)\n",
    "rf_weighted_report = classification_report(y_test, rf_wighted_pred)\n",
    "csv_report(rf_weighted_report, \"rf_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "944ca2c5-faa9-40e7-8b12-02af184a3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise and run model using a grid search to find parameters, and evaluating using f1-score with cross-validation.\n",
    "nb = MultinomialNB()\n",
    "nb_params = {'alpha': [0.1, 1, 10],\n",
    "             'fit_prior': [True, False]}\n",
    "\n",
    "nb_grid = GridSearchCV(nb, nb_params, cv=5, scoring=\"f1_macro\")\n",
    "nb_grid.fit(X_train, y_train)\n",
    "nb_best_params = nb_grid.best_params_\n",
    "\n",
    "best_nb = MultinomialNB(**nb_best_params)\n",
    "best_nb.fit(X_train, y_train)\n",
    "nb_pred = best_nb.predict(X_test)\n",
    "nb_report = classification_report(y_test, nb_pred)\n",
    "csv_report(nb_report, \"nb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b70f7d94-2b59-4c56-add1-4553b497b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_weighted = MultinomialNB(**nb_best_params, class_prior=class_weights)\n",
    "nb_weighted.fit(X_train, y_train)\n",
    "nb_weighted_pred = nb_weighted.predict(X_test)\n",
    "nb_weighted_report = classification_report(y_test, nb_weighted_pred)\n",
    "csv_report(nb_weighted_report, \"nb_weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
